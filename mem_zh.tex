\section{内存管理} \label{memory management}

Linux的内存管理可以分为内存分配和虚拟内存两个部分.\cite{silberschatz2021operating}
因为Linux采用分页的方式管理内存，内存分配部分的主要任务就是分配物理页、释放物理页.
而虚拟内存部分利用分配出来的物理页来提供内存的抽象，
实现缓存、共享和保护等功能.

\subsection{物理页面的管理}

\subsubsection{物理内存模型}
Linux的内存管理是基于分页技术的，因此物理内存均被看作是页面的数组.
但是物理内存的组织形式又是架构相关的，而且一种架构可以有多种组织方式.
Linux针对不同的物理内存形式，用不同的物理内存模型来管理.
大部分连续的内存对应FLATMEM\index{FLATMEM}模型，
更复杂的内存组织形式对应SPARSEMEM模型.\cite{Physical36:online}
x86-64支持这两种形式，但是FLATMEM不支持非统一内存访问架构（NUMA）\index{NUMA}机器.
Arch Linux和绝大多数x86-64发行版都%
\archlinuxconf{994}{配置}的是SPARSEMEM模型.

SPARSEMEM\index{SPARSEMEM}模型下，物理内存的配置可以很灵活.
物理内存被分段表示，每一个段（section）指向连续存放的一系列物理页面.
内核中管理物理页面的程序\archlinuxconf{995}{可以}存储在动态分配的数组中，
因此甚至可以支持运行时添加内存设备.
配置的灵活性却会给物理内存的访问增加复杂性，
在物理内存不连续的条件下，物理页号（PFN）\index{PFN}并不能用于直接访问真正的物理页.
物理页号到物理页的映射方式有两种，
一种方式是把section的信息编码进PFN中，并且在 \lstinline{struct page}
中也记录section的值.
而默认配置下，例如Arch Linux \archlinuxconf{996}{使用}的是VMEMMAP\index{VMEMMAP} 方式.
这是指在虚拟内存中专门分配一个连续的称作virtual memory map的空间来存放页面信息.
Virtual memory map是页面信息
\lstinline{struct page}\index{p@\lstinline{struct page}}
的一维数组，
以PFN为元素下标，所以要想从PFN找到页面信息（包含页面的物理地址），
只需要计算偏移访问数组即可.
逻辑上，这个数组内有所有的页面的信息，而且是连续的，其大小可与整个物理地址空间的大小相比.
但是，正是因为它是虚拟地址空间的连续数组，而虚拟的页面又可以按需分配，
所以它并不会真正占据很多空间.
这种在物理页面管理中也使用虚拟内存的想法非常能体现虚拟内存的灵活性.

\begin{readsrcbox}{\lstinline{struct page}，内存模型}
	\lstinline{struct page} 是存储物理页面的信息的结构体.
	其中包括物理页面的地址，分配和回收页面需要的信息等，
	定义在 \linuxsrc{include/linux/mm_types.h}.

	虚拟地址到物理地址的映射需要用PFN来找到物理页面，
	这就需要用PFN算出对应的 \lstinline{struct page}，
	完成PFN和 \lstinline{page} 之间的转换的是宏
	\lstinline{pfn_to_page} 和 \lstinline{page_to_pfn}，
	不同的物理内存模型的实现不同，内存模型相关定义可见
	\linuxsrc{include/asm-generic/memory_model.h}.
	其中VMEMMAP由于有虚拟地址上连续的\lstinline{vmemmap}，
	其转换过程就是涉及数组元素偏移量的简单计算：
	\begin{lstlisting}[language=C]
/* include/asm-generic/memory_model.h */
#define __pfn_to_page(pfn)	(vmemmap + (pfn))
#define __page_to_pfn(page)	(unsigned long)((page) - vmemmap)
\end{lstlisting}

	SPARSEMEM的VMEMMAP模型下，
	\lstinline{struct page *vmemmap} 由架构相关的代码定义.
	x86-64的位于 \linuxsrc{arch/x86/include/asm/pgtable_64.h}.
	架构无关的用于填充 \lstinline{vmemmap} 的代码位于
	\linuxsrc{mm/sparse-vmemmap.c}.
\end{readsrcbox}

分section的SPARSEMEM内存模型解决了物理内存的差异性，
那么分配页面时如何区分具有不同功能的内存呢？
答案是内存的不同区域还有ZONE的区分.
有些设备不能访问整个地址空间，导致只有一部分地址可以用于直接内存访问DMA\index{DMA}.
这一部分内存被设置为 \lstinline{ZONE_DMA} 或 \lstinline{ZONE_DMA32}.
另外，一些物理地址只是用于访问设备，而不是真正的内存地址，
这些空间被设置为 \lstinline{ZONE_DEVICE}，其中的页面永远不会成为空闲页面.
其他的页面都可以用来当作普通的内存来分配，称为 \lstinline{ZONE_NORMAL}.
Linux内核中的物理页面分配代码被称作zoned page allocator，\index{zoned allocator}
是因为每一个zone是被单独管理的，各个zone之间的分配互不干扰.

\subsubsection{页面分配器}

在每一个zone内部，分配器主要实现两个功能：分配页面和释放页面，
即根据调用者的需要找到一定数量的空闲的页面，向调用者返回分配的页面的地址，并把这些页面记录为正在使用，
在调用者使用完这些页面后，再向分配器归还这些页面，使他们重新变为可以分配的空闲页面.

在分配问题\cite{silberschatz2021operating}\index{allocation problem}中，
要避免的是碎片化问题\index{fragmentation}.
页面分配器只关心外碎片化问题\index{external fragmentation}，
因为其并不管理页面内部的内存组织方式.
外碎片化问题——无法找到需要的大小的空间即使总的空闲空间能够满足要求\cite{silberschatz2021operating}
——出现的原因是较小的已分配区域散落在不连续的区域中，导致没有大块的空间来满足分配要求.
既然问题出在小区域“割裂”大区域上，那么尽量减少分割的次数、并且尽可能多地合并就可以降低外碎片化程度.
Linux的页面分配器采用的“伙伴系统”（buddy system）\index{buddy system}就是这样的一个分配算法.

伙伴系统的主要思想是为不同大小的空闲内存块分别维护一个列表，方便直接找到所需大小的空闲块，
并且多个小的块在被释放后可以合并为大的块，而大的块如果需要也可以很方便地分割成小的块.
具体的要求是这样的：
块的大小必须为页面大小的 $2^k$ 倍（$k$为自然数），其中 $k$ 被称为块的次%
\footnote{order. 类似于多项式的次，如 $x^3$ 为3次多项式，故我翻译成“次”，
	$k$ 次的块有 $2^k$ 个页面.}；
如果要求的页面数量 $n'$ 不为2的幂，
则也要分配最小的满足要求的2的整数幂的数量的页面，即分配的页面的数量 $n$ 满足：
\begin{equation*}
	n = 2^k = 2^{\lceil log_{2}{n'}\rceil}
\end{equation*}
假设内存的容量为$2^m$，所有页面都是空闲的时候，整个内存为一个 $m$ 次的块.
每次分割空闲块的时候都是对半分割\footnote{split.}，一个 $k$ 次的块可以分割成两个 $k-1$ 次的较小的块.
为了减少碎片，每当两个原本是从同一个 $k$ 次块分割出来的两个 $k-1$ 次的块都空闲时，
它们就会被重新合并\footnote{Knuth称为coalesce，Linux内核称为merge.}%
成原来的 $k$ 次的较大块.
这样的两个相邻的块就是一对\emph{伙伴}.\index{buddy}
互为伙伴的两个块的次数一定相等，位置一定相邻.
但是次数相等、位置相邻的块不一定互为伙伴.
只有伙伴可以合并的规则保证了合并产生的块一定是按该块的大小对齐的，
再结合对半分割的规则，可以推出：
所有的块都是按其大小对齐的.
块的对齐对减少碎片化程度也有帮助.
\cite{taocp1}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "linux_zh"
%%% End:
